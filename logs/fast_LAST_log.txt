layer1_out 500, delta 10, sigma 0.1, sim nnlsw, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07548586279153824
val loss: 0.07502114772796631
EPOCH 21
train loss: 0.06494779139757156
val loss: 0.06350202113389969
EPOCH 41
train loss: 0.06414680182933807
val loss: 0.06291896104812622
EPOCH 61
train loss: 0.06376302242279053
val loss: 0.0627826452255249
EPOCH 81
train loss: 0.06322824954986572
val loss: 0.06254451721906662
EPOCH 101
train loss: 0.062317147850990295
val loss: 0.0618041567504406
EPOCH 121
train loss: 0.06095156818628311
val loss: 0.06059754267334938
EPOCH 141
train loss: 0.05936102569103241
val loss: 0.05913976952433586
EPOCH 161
train loss: 0.05792311578989029
val loss: 0.05784611031413078
EPOCH 181
train loss: 0.05683087557554245
val loss: 0.05695036053657532
2-NN
0.4303519061583578
5-NN
0.46187683284457476
8-NN
0.46725317693059626
10-NN
0.4687194525904203
15-NN
0.47287390029325516
layer1_out 500, delta 10, sigma 0.1, sim nnlsw, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07586076855659485
val loss: 0.07362116873264313
EPOCH 21
train loss: 0.06490357220172882
val loss: 0.06387902051210403
EPOCH 41
train loss: 0.06414370238780975
val loss: 0.06308016926050186
EPOCH 61
train loss: 0.06374754756689072
val loss: 0.06288836151361465
EPOCH 81
train loss: 0.06320317089557648
val loss: 0.06258779019117355
EPOCH 101
train loss: 0.062298063188791275
val loss: 0.061945848166942596
EPOCH 121
train loss: 0.06093741953372955
val loss: 0.06082363799214363
EPOCH 141
train loss: 0.059309620410203934
val loss: 0.05945022776722908
EPOCH 161
train loss: 0.057784777134656906
val loss: 0.05814511328935623
EPOCH 181
train loss: 0.0565917082130909
val loss: 0.05723773315548897
2-NN
0.4305962854349951
5-NN
0.4655425219941349
8-NN
0.4718963831867058
10-NN
0.4726295210166178
15-NN
0.47043010752688175
layer1_out 500, delta 10, sigma 0.1, sim nnlsw, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07509128749370575
val loss: 0.07557563483715057
EPOCH 21
train loss: 0.06424196809530258
val loss: 0.06569236516952515
EPOCH 41
train loss: 0.06256546080112457
val loss: 0.06505556404590607
EPOCH 61
train loss: 0.06081557273864746
val loss: 0.0648786872625351
EPOCH 81
train loss: 0.05867213010787964
val loss: 0.06463395059108734
EPOCH 101
train loss: 0.056204456835985184
val loss: 0.06418577581644058
EPOCH 121
train loss: 0.053491223603487015
val loss: 0.06345319747924805
EPOCH 141
train loss: 0.050864942371845245
val loss: 0.06266256421804428
EPOCH 161
train loss: 0.048724398016929626
val loss: 0.062166593968868256
EPOCH 181
train loss: 0.047151293605566025
val loss: 0.06220049411058426
2-NN
0.36656891495601174
5-NN
0.38391984359726294
8-NN
0.3836754643206256
10-NN
0.3848973607038123
15-NN
0.3758553274682307
layer1_out 500, delta 10, sigma 0.1, sim gaussian, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07590697705745697
val loss: 0.07643540948629379
EPOCH 21
train loss: 0.06398040056228638
val loss: 0.06513287872076035
EPOCH 41
train loss: 0.061532046645879745
val loss: 0.06471824645996094
early stopping...
2-NN
0.34384164222873903
5-NN
0.36974584555229717
8-NN
0.36534701857282503
10-NN
0.3651026392961877
15-NN
0.3633919843597263
layer1_out 500, delta 10, sigma 0.1, sim gaussian, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07656479626893997
val loss: 0.07165348529815674
EPOCH 21
train loss: 0.06458182632923126
val loss: 0.061497461050748825
EPOCH 41
train loss: 0.06190023198723793
val loss: 0.06091633066534996
early stopping...
2-NN
0.3355327468230694
5-NN
0.3699902248289345
8-NN
0.3616813294232649
10-NN
0.3633919843597263
15-NN
0.3616813294232649
layer1_out 500, delta 10, sigma 0.1, sim gaussian, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07609886676073074
val loss: 0.07101664692163467
EPOCH 21
train loss: 0.06406890600919724
val loss: 0.06218632310628891
EPOCH 41
train loss: 0.061602525413036346
val loss: 0.061871860176324844
early stopping...
2-NN
0.3443304007820137
5-NN
0.3663245356793744
8-NN
0.35997067448680353
10-NN
0.35654936461388076
15-NN
0.3550830889540567
layer1_out 500, delta 10, sigma 0.1, sim MSTKNN, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: nan
val loss: nan
EPOCH 21
train loss: nan
val loss: nan
EPOCH 41
train loss: nan
val loss: nan
EPOCH 61
train loss: nan
val loss: nan
EPOCH 81
train loss: nan
val loss: nan
EPOCH 101
train loss: nan
val loss: nan
EPOCH 121
train loss: nan
val loss: nan
EPOCH 141
train loss: nan
val loss: nan
EPOCH 161
train loss: nan
val loss: nan
EPOCH 181
train loss: nan
val loss: nan
layer1_out 500, delta 10, sigma 0.1, sim MSTKNN, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: nan
val loss: nan
EPOCH 21
train loss: nan
val loss: nan
EPOCH 41
train loss: nan
val loss: nan
EPOCH 61
train loss: nan
val loss: nan
EPOCH 81
train loss: nan
val loss: nan
EPOCH 101
train loss: nan
val loss: nan
EPOCH 121
train loss: nan
val loss: nan
EPOCH 141
train loss: nan
val loss: nan
EPOCH 161
train loss: nan
val loss: nan
EPOCH 181
train loss: nan
val loss: nan
layer1_out 500, delta 10, sigma 0.1, sim MSTKNN, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: nan
val loss: nan
EPOCH 21
train loss: nan
val loss: nan
EPOCH 41
train loss: nan
val loss: nan
EPOCH 61
train loss: nan
val loss: nan
EPOCH 81
train loss: nan
val loss: nan
EPOCH 101
train loss: nan
val loss: nan
EPOCH 121
train loss: nan
val loss: nan
EPOCH 141
train loss: nan
val loss: nan
EPOCH 161
train loss: nan
val loss: nan
EPOCH 181
train loss: nan
val loss: nan
layer1_out 500, delta 10, sigma 0.9, sim nnlsw, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07433974742889404
val loss: 0.08259551972150803
EPOCH 21
train loss: 0.06408943980932236
val loss: 0.07132331281900406
EPOCH 41
train loss: 0.0632876455783844
val loss: 0.07078129053115845
EPOCH 61
train loss: 0.06291580200195312
val loss: 0.07058156281709671
EPOCH 81
train loss: 0.06238018721342087
val loss: 0.07027915865182877
EPOCH 101
train loss: 0.06144426017999649
val loss: 0.0695251077413559
EPOCH 121
train loss: 0.06004566326737404
val loss: 0.06827674806118011
EPOCH 141
train loss: 0.05843041092157364
val loss: 0.06678234040737152
EPOCH 161
train loss: 0.05698614940047264
val loss: 0.06545810401439667
EPOCH 181
train loss: 0.05592428892850876
val loss: 0.0645667314529419
2-NN
0.4252199413489736
5-NN
0.46065493646138805
8-NN
0.46480938416422285
10-NN
0.46847507331378296
15-NN
0.4731182795698925
layer1_out 500, delta 10, sigma 0.9, sim nnlsw, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07567156851291656
val loss: 0.07857315987348557
EPOCH 21
train loss: 0.06454342603683472
val loss: 0.06769108027219772
EPOCH 41
train loss: 0.06370875984430313
val loss: 0.0670471265912056
EPOCH 61
train loss: 0.06334814429283142
val loss: 0.06686248630285263
EPOCH 81
train loss: 0.0628473237156868
val loss: 0.06663493812084198
EPOCH 101
train loss: 0.06201246753334999
val loss: 0.06613623350858688
EPOCH 121
train loss: 0.06075615435838699
val loss: 0.06524121016263962
EPOCH 141
train loss: 0.059233713895082474
val loss: 0.06408192217350006
EPOCH 161
train loss: 0.05776113271713257
val loss: 0.06295759975910187
EPOCH 181
train loss: 0.0565606988966465
val loss: 0.062072765082120895
2-NN
0.437683284457478
5-NN
0.4726295210166178
8-NN
0.4767839687194526
10-NN
0.47629521016617793
15-NN
0.4797165200391007
layer1_out 500, delta 10, sigma 0.9, sim nnlsw, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07497558742761612
val loss: 0.08150386065244675
EPOCH 21
train loss: 0.0638376772403717
val loss: 0.07080060988664627
EPOCH 41
train loss: 0.062079522758722305
val loss: 0.07012972980737686
early stopping...
2-NN
0.4120234604105572
5-NN
0.4479472140762463
8-NN
0.4538123167155425
10-NN
0.45772238514173996
15-NN
0.4447702834799609
layer1_out 500, delta 10, sigma 0.9, sim gaussian, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.0755082368850708
val loss: 0.07956796139478683
EPOCH 21
train loss: 0.06415463238954544
val loss: 0.07004321366548538
EPOCH 41
train loss: 0.06353780627250671
val loss: 0.0693066269159317
EPOCH 61
train loss: 0.06334058940410614
val loss: 0.06916750967502594
EPOCH 81
train loss: 0.06311791390180588
val loss: 0.06896965950727463
EPOCH 101
train loss: 0.06271781772375107
val loss: 0.068592369556427
EPOCH 121
train loss: 0.06203004717826843
val loss: 0.06797299534082413
EPOCH 141
train loss: 0.061051759868860245
val loss: 0.06709985435009003
EPOCH 161
train loss: 0.05990182235836983
val loss: 0.06607013940811157
EPOCH 181
train loss: 0.058782439678907394
val loss: 0.06512001901865005
2-NN
0.2859237536656892
5-NN
0.33357771260997066
8-NN
0.3616813294232649
10-NN
0.35581622678396874
15-NN
0.3560606060606061
layer1_out 500, delta 10, sigma 0.9, sim gaussian, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07562366873025894
val loss: 0.07629590481519699
EPOCH 21
train loss: 0.06491339206695557
val loss: 0.06517321616411209
EPOCH 41
train loss: 0.0640454813838005
val loss: 0.06434828042984009
EPOCH 61
train loss: 0.06382563710212708
val loss: 0.06412412226200104
EPOCH 81
train loss: 0.06356986612081528
val loss: 0.06387800723314285
EPOCH 101
train loss: 0.06308590620756149
val loss: 0.06339745223522186
EPOCH 121
train loss: 0.062229499220848083
val loss: 0.06252778321504593
EPOCH 141
train loss: 0.06102026253938675
val loss: 0.06131055951118469
EPOCH 161
train loss: 0.05967484042048454
val loss: 0.05993667244911194
EPOCH 181
train loss: 0.05848044902086258
val loss: 0.05872955918312073
2-NN
0.28983382209188663
5-NN
0.3225806451612903
8-NN
0.3267350928641251
10-NN
0.33064516129032256
15-NN
0.33944281524926684
layer1_out 500, delta 10, sigma 0.9, sim gaussian, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.0751829668879509
val loss: 0.07928188145160675
EPOCH 21
train loss: 0.06398443877696991
val loss: 0.06797752529382706
EPOCH 41
train loss: 0.06251667439937592
val loss: 0.06755390018224716
EPOCH 61
train loss: 0.061020661145448685
val loss: 0.06743913143873215
EPOCH 81
train loss: 0.059135422110557556
val loss: 0.06727006286382675
EPOCH 101
train loss: 0.05687084421515465
val loss: 0.06686700880527496
EPOCH 121
train loss: 0.0542999804019928
val loss: 0.06610657274723053
EPOCH 141
train loss: 0.05172191560268402
val loss: 0.06520259380340576
EPOCH 161
train loss: 0.04953279346227646
val loss: 0.06451654434204102
EPOCH 181
train loss: 0.04790123924612999
val loss: 0.06428857892751694
2-NN
0.31207233626588465
5-NN
0.3326001955034213
8-NN
0.3399315738025415
10-NN
0.33822091886608013
15-NN
0.3357771260997067
layer1_out 500, delta 10, sigma 0.9, sim MSTKNN, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07582885771989822
val loss: 0.0725783035159111
EPOCH 21
train loss: 0.06528086960315704
val loss: 0.06264384090900421
EPOCH 41
train loss: 0.06435474008321762
val loss: 0.06186596304178238
EPOCH 61
train loss: 0.06406300514936447
val loss: 0.06165679171681404
EPOCH 81
train loss: 0.06372196227312088
val loss: 0.06149590387940407
EPOCH 101
train loss: 0.06315093487501144
val loss: 0.061067983508110046
EPOCH 121
train loss: 0.0622028149664402
val loss: 0.060249973088502884
EPOCH 141
train loss: 0.06091327220201492
val loss: 0.059082236140966415
EPOCH 161
train loss: 0.05954898148775101
val loss: 0.05783998593688011
EPOCH 181
train loss: 0.05839997157454491
val loss: 0.056795570999383926
2-NN
0.35532746823069405
5-NN
0.4083577712609971
8-NN
0.43206256109481916
10-NN
0.4335288367546432
15-NN
0.44208211143695014
layer1_out 500, delta 10, sigma 0.9, sim MSTKNN, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07517977803945541
val loss: 0.08198877424001694
EPOCH 21
train loss: 0.06416984647512436
val loss: 0.07038610428571701
EPOCH 41
train loss: 0.06347182393074036
val loss: 0.06992361694574356
EPOCH 61
train loss: 0.06317613273859024
val loss: 0.06974032521247864
EPOCH 81
train loss: 0.06280230730772018
val loss: 0.06951341032981873
EPOCH 101
train loss: 0.062138427048921585
val loss: 0.0689484179019928
EPOCH 121
train loss: 0.06107056140899658
val loss: 0.06794201582670212
EPOCH 141
train loss: 0.05970994010567665
val loss: 0.06659824401140213
EPOCH 161
train loss: 0.05835666507482529
val loss: 0.06523466855287552
EPOCH 181
train loss: 0.05728515610098839
val loss: 0.0641581192612648
2-NN
0.35997067448680353
5-NN
0.41715542521994137
8-NN
0.43670576735092864
10-NN
0.43621700879765396
15-NN
0.4411045943304008
layer1_out 500, delta 10, sigma 0.9, sim MSTKNN, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07550918310880661
val loss: 0.07746858894824982
EPOCH 21
train loss: 0.0643756240606308
val loss: 0.06683081388473511
EPOCH 41
train loss: 0.06255127489566803
val loss: 0.06609667837619781
EPOCH 61
train loss: 0.06091323494911194
val loss: 0.0660301148891449
EPOCH 81
train loss: 0.0589110367000103
val loss: 0.06592781096696854
EPOCH 101
train loss: 0.05657188966870308
val loss: 0.06560944765806198
EPOCH 121
train loss: 0.0539805069565773
val loss: 0.06493473052978516
EPOCH 141
train loss: 0.051406826823949814
val loss: 0.06412964314222336
EPOCH 161
train loss: 0.04924715682864189
val loss: 0.06351149082183838
EPOCH 181
train loss: 0.0476284921169281
val loss: 0.06333043426275253
2-NN
0.34995112414467255
5-NN
0.38220918866080156
8-NN
0.37854349951124144
10-NN
0.3787878787878788
15-NN
0.36901270772238515
layer1_out 500, delta 20, sigma 0.1, sim nnlsw, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07515662163496017
val loss: 0.07532654702663422
EPOCH 21
train loss: 0.06464545428752899
val loss: 0.06548455357551575
EPOCH 41
train loss: 0.0639299675822258
val loss: 0.06482063233852386
EPOCH 61
train loss: 0.06354709714651108
val loss: 0.06465304642915726
EPOCH 81
train loss: 0.06301358342170715
val loss: 0.0643743947148323
EPOCH 101
train loss: 0.06210504472255707
val loss: 0.06374650448560715
EPOCH 121
train loss: 0.060738224536180496
val loss: 0.06267774850130081
EPOCH 141
train loss: 0.0591329000890255
val loss: 0.06138581037521362
EPOCH 161
train loss: 0.05767827481031418
val loss: 0.06021583825349808
EPOCH 181
train loss: 0.05659068375825882
val loss: 0.0593864731490612
2-NN
0.4244868035190616
5-NN
0.4640762463343108
8-NN
0.46114369501466274
10-NN
0.4626099706744868
15-NN
0.46652003910068424
layer1_out 500, delta 20, sigma 0.1, sim nnlsw, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07496728748083115
val loss: 0.07704714685678482
EPOCH 21
train loss: 0.06455012410879135
val loss: 0.06671947985887527
EPOCH 41
train loss: 0.06375634670257568
val loss: 0.06598223745822906
EPOCH 61
train loss: 0.06332496553659439
val loss: 0.06583038717508316
EPOCH 81
train loss: 0.06270357966423035
val loss: 0.06549021601676941
EPOCH 101
train loss: 0.06164245307445526
val loss: 0.06471575796604156
EPOCH 121
train loss: 0.06006980314850807
val loss: 0.06343235075473785
EPOCH 141
train loss: 0.05829455330967903
val loss: 0.0619230791926384
EPOCH 161
train loss: 0.05679517239332199
val loss: 0.06065750867128372
EPOCH 181
train loss: 0.05573442578315735
val loss: 0.05985218286514282
2-NN
0.43499511241446726
5-NN
0.46065493646138805
8-NN
0.4696969696969697
10-NN
0.4814271749755621
15-NN
0.47825024437927666
layer1_out 500, delta 20, sigma 0.1, sim nnlsw, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07478645443916321
val loss: 0.08150696754455566
EPOCH 21
train loss: 0.0637466087937355
val loss: 0.07154367864131927
EPOCH 41
train loss: 0.061931055039167404
val loss: 0.07075406610965729
EPOCH 61
train loss: 0.06018254905939102
val loss: 0.07066497206687927
EPOCH 81
train loss: 0.05810247361660004
val loss: 0.07065312564373016
EPOCH 101
train loss: 0.055742405354976654
val loss: 0.07048767060041428
EPOCH 121
train loss: 0.05316485837101936
val loss: 0.06995265930891037
EPOCH 141
train loss: 0.050623953342437744
val loss: 0.06925911456346512
EPOCH 161
train loss: 0.048469193279743195
val loss: 0.0686730369925499
EPOCH 181
train loss: 0.04683161526918411
val loss: 0.06844254583120346
2-NN
0.37194525904203324
5-NN
0.38807429130009774
8-NN
0.3895405669599218
10-NN
0.39002932551319647
15-NN
0.38025415444770283
layer1_out 500, delta 20, sigma 0.1, sim gaussian, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07560086995363235
val loss: 0.07398954033851624
EPOCH 21
train loss: 0.06403971463441849
val loss: 0.06424209475517273
EPOCH 41
train loss: 0.061576735228300095
val loss: 0.06366322934627533
early stopping...
2-NN
0.3489736070381232
5-NN
0.3709677419354839
8-NN
0.375366568914956
10-NN
0.37927663734115347
15-NN
0.36901270772238515
layer1_out 500, delta 20, sigma 0.1, sim gaussian, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07594075053930283
val loss: 0.07617004960775375
EPOCH 21
train loss: 0.06381364911794662
val loss: 0.06546880304813385
EPOCH 41
train loss: 0.061365991830825806
val loss: 0.06488603353500366
early stopping...
2-NN
0.34872922776148585
5-NN
0.3682795698924731
8-NN
0.3692570869990225
10-NN
0.3651026392961877
15-NN
0.3621700879765396
layer1_out 500, delta 20, sigma 0.1, sim gaussian, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07595832645893097
val loss: 0.0769432783126831
EPOCH 21
train loss: 0.06372340023517609
val loss: 0.06608263403177261
EPOCH 41
train loss: 0.06131718307733536
val loss: 0.06562597304582596
early stopping...
2-NN
0.3633919843597263
5-NN
0.3812316715542522
8-NN
0.3787878787878788
10-NN
0.3770772238514174
15-NN
0.36974584555229717
layer1_out 500, delta 20, sigma 0.1, sim MSTKNN, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: nan
val loss: nan
EPOCH 21
train loss: nan
val loss: nan
EPOCH 41
train loss: nan
val loss: nan
EPOCH 61
train loss: nan
val loss: nan
EPOCH 81
train loss: nan
val loss: nan
EPOCH 101
train loss: nan
val loss: nan
EPOCH 121
train loss: nan
val loss: nan
EPOCH 141
train loss: nan
val loss: nan
EPOCH 161
train loss: nan
val loss: nan
EPOCH 181
train loss: nan
val loss: nan
layer1_out 500, delta 20, sigma 0.1, sim MSTKNN, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: nan
val loss: nan
EPOCH 21
train loss: nan
val loss: nan
EPOCH 41
train loss: nan
val loss: nan
EPOCH 61
train loss: nan
val loss: nan
EPOCH 81
train loss: nan
val loss: nan
EPOCH 101
train loss: nan
val loss: nan
EPOCH 121
train loss: nan
val loss: nan
EPOCH 141
train loss: nan
val loss: nan
EPOCH 161
train loss: nan
val loss: nan
EPOCH 181
train loss: nan
val loss: nan
layer1_out 500, delta 20, sigma 0.1, sim MSTKNN, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: nan
val loss: nan
EPOCH 21
train loss: nan
val loss: nan
EPOCH 41
train loss: nan
val loss: nan
EPOCH 61
train loss: nan
val loss: nan
EPOCH 81
train loss: nan
val loss: nan
EPOCH 101
train loss: nan
val loss: nan
EPOCH 121
train loss: nan
val loss: nan
EPOCH 141
train loss: nan
val loss: nan
EPOCH 161
train loss: nan
val loss: nan
EPOCH 181
train loss: nan
val loss: nan
layer1_out 500, delta 20, sigma 0.9, sim nnlsw, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07599275559186935
val loss: 0.0748601034283638
EPOCH 21
train loss: 0.06488221138715744
val loss: 0.06444890052080154
EPOCH 41
train loss: 0.06414232403039932
val loss: 0.06369617581367493
EPOCH 61
train loss: 0.06380203366279602
val loss: 0.06351687014102936
EPOCH 81
train loss: 0.06336085498332977
val loss: 0.06332656741142273
EPOCH 101
train loss: 0.06261593848466873
val loss: 0.06283923983573914
EPOCH 121
train loss: 0.061454031616449356
val loss: 0.061960749328136444
EPOCH 141
train loss: 0.059987399727106094
val loss: 0.060777388513088226
EPOCH 161
train loss: 0.05850493535399437
val loss: 0.059561196714639664
EPOCH 181
train loss: 0.057264070957899094
val loss: 0.058599382638931274
2-NN
0.4215542521994135
5-NN
0.45943304007820135
8-NN
0.4674975562072336
10-NN
0.4670087976539589
15-NN
0.47214076246334313
layer1_out 500, delta 20, sigma 0.9, sim nnlsw, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07644644379615784
val loss: 0.07311001420021057
EPOCH 21
train loss: 0.06522954255342484
val loss: 0.06137073412537575
EPOCH 41
train loss: 0.0644131749868393
val loss: 0.06099706143140793
EPOCH 61
train loss: 0.06403248012065887
val loss: 0.06080857664346695
EPOCH 81
train loss: 0.06351306289434433
val loss: 0.060595810413360596
EPOCH 101
train loss: 0.06264813989400864
val loss: 0.06010556221008301
EPOCH 121
train loss: 0.06132118031382561
val loss: 0.059145085513591766
EPOCH 141
train loss: 0.05967960134148598
val loss: 0.05787665396928787
EPOCH 161
train loss: 0.05809759348630905
val loss: 0.056637611240148544
EPOCH 181
train loss: 0.05685890465974808
val loss: 0.05568670108914375
2-NN
0.4381720430107527
5-NN
0.46358748778103614
8-NN
0.4833822091886608
10-NN
0.47873900293255134
15-NN
0.47996089931573804
layer1_out 500, delta 20, sigma 0.9, sim nnlsw, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07560339570045471
val loss: 0.07156242430210114
EPOCH 21
train loss: 0.0647614449262619
val loss: 0.062131039798259735
EPOCH 41
train loss: 0.0629880353808403
val loss: 0.061276596039533615
EPOCH 61
train loss: 0.06127239391207695
val loss: 0.061253778636455536
EPOCH 81
train loss: 0.059183184057474136
val loss: 0.0612863264977932
EPOCH 101
train loss: 0.056769419461488724
val loss: 0.06125819683074951
EPOCH 121
train loss: 0.05411473661661148
val loss: 0.060962218791246414
EPOCH 141
train loss: 0.05149249732494354
val loss: 0.060673199594020844
EPOCH 161
train loss: 0.04927624762058258
val loss: 0.06048348918557167
EPOCH 181
train loss: 0.04758703336119652
val loss: 0.06062820181250572
2-NN
0.36974584555229717
5-NN
0.3956500488758553
8-NN
0.39711632453567935
10-NN
0.3924731182795699
15-NN
0.3787878787878788
layer1_out 500, delta 20, sigma 0.9, sim gaussian, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07520769536495209
val loss: 0.07707618176937103
EPOCH 21
train loss: 0.06470204144716263
val loss: 0.06646096706390381
EPOCH 41
train loss: 0.06386784464120865
val loss: 0.06593567132949829
EPOCH 61
train loss: 0.0636405274271965
val loss: 0.0657077208161354
EPOCH 81
train loss: 0.06337369233369827
val loss: 0.0654444769024849
EPOCH 101
train loss: 0.06288683414459229
val loss: 0.06498555094003677
EPOCH 121
train loss: 0.062065526843070984
val loss: 0.06421367824077606
EPOCH 141
train loss: 0.060939300805330276
val loss: 0.06317336857318878
EPOCH 161
train loss: 0.05969814583659172
val loss: 0.06204115226864815
EPOCH 181
train loss: 0.05857926979660988
val loss: 0.06104844808578491
2-NN
0.290811339198436
5-NN
0.3416422287390029
8-NN
0.3509286412512219
10-NN
0.3604594330400782
15-NN
0.35581622678396874
layer1_out 500, delta 20, sigma 0.9, sim gaussian, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07566796988248825
val loss: 0.07415179908275604
EPOCH 21
train loss: 0.06491590291261673
val loss: 0.0634639784693718
EPOCH 41
train loss: 0.06423156708478928
val loss: 0.06283217668533325
EPOCH 61
train loss: 0.06403012573719025
val loss: 0.0626361295580864
EPOCH 81
train loss: 0.06378480046987534
val loss: 0.06240022927522659
EPOCH 101
train loss: 0.06332612782716751
val loss: 0.061959147453308105
EPOCH 121
train loss: 0.06252934038639069
val loss: 0.061188310384750366
EPOCH 141
train loss: 0.06139233708381653
val loss: 0.060072850435972214
EPOCH 161
train loss: 0.060093533247709274
val loss: 0.058782774955034256
EPOCH 181
train loss: 0.05890073999762535
val loss: 0.05762328580021858
2-NN
0.2768817204301075
5-NN
0.32820136852394916
8-NN
0.33357771260997066
10-NN
0.3301564027370479
15-NN
0.3374877810361681
layer1_out 500, delta 20, sigma 0.9, sim gaussian, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07657002657651901
val loss: 0.07373858988285065
EPOCH 21
train loss: 0.06481987982988358
val loss: 0.06289936602115631
EPOCH 41
train loss: 0.06329739093780518
val loss: 0.06226912513375282
EPOCH 61
train loss: 0.06190192326903343
val loss: 0.06212743744254112
EPOCH 81
train loss: 0.06008952483534813
val loss: 0.06193985044956207
EPOCH 101
train loss: 0.05790269374847412
val loss: 0.061593908816576004
EPOCH 121
train loss: 0.05542249605059624
val loss: 0.06094196066260338
EPOCH 141
train loss: 0.05285610258579254
val loss: 0.06008594110608101
EPOCH 161
train loss: 0.050583064556121826
val loss: 0.059331510215997696
EPOCH 181
train loss: 0.04881066083908081
val loss: 0.05895509943366051
2-NN
0.31133919843597263
5-NN
0.33479960899315736
8-NN
0.3326001955034213
10-NN
0.33479960899315736
15-NN
0.34066471163245354
layer1_out 500, delta 20, sigma 0.9, sim MSTKNN, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.0749875083565712
val loss: 0.07867106795310974
EPOCH 21
train loss: 0.06432774662971497
val loss: 0.06856423616409302
EPOCH 41
train loss: 0.06369205564260483
val loss: 0.0679364949464798
EPOCH 61
train loss: 0.0634562224149704
val loss: 0.06780627369880676
EPOCH 81
train loss: 0.06316271424293518
val loss: 0.06762511283159256
EPOCH 101
train loss: 0.06265672296285629
val loss: 0.06722454726696014
EPOCH 121
train loss: 0.061830878257751465
val loss: 0.06649018824100494
EPOCH 141
train loss: 0.060706403106451035
val loss: 0.06544923782348633
EPOCH 161
train loss: 0.05945490300655365
val loss: 0.0642768070101738
EPOCH 181
train loss: 0.05830490216612816
val loss: 0.06317327916622162
2-NN
0.35581622678396874
5-NN
0.4032258064516129
8-NN
0.4239980449657869
10-NN
0.4281524926686217
15-NN
0.43328445747800587
layer1_out 500, delta 20, sigma 0.9, sim MSTKNN, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.0759500190615654
val loss: 0.07191170006990433
EPOCH 21
train loss: 0.06511834263801575
val loss: 0.06148497387766838
EPOCH 41
train loss: 0.06441997736692429
val loss: 0.06091305986046791
EPOCH 61
train loss: 0.0641222819685936
val loss: 0.06076808646321297
EPOCH 81
train loss: 0.06374067813158035
val loss: 0.060586001724004745
EPOCH 101
train loss: 0.06306430697441101
val loss: 0.06004924699664116
EPOCH 121
train loss: 0.0619637630879879
val loss: 0.059096723794937134
EPOCH 141
train loss: 0.060529325157403946
val loss: 0.05785304680466652
EPOCH 161
train loss: 0.059073060750961304
val loss: 0.05658279359340668
EPOCH 181
train loss: 0.057907573878765106
val loss: 0.05563301593065262
2-NN
0.36608015640273706
5-NN
0.4232649071358749
8-NN
0.4310850439882698
10-NN
0.4364613880742913
15-NN
0.44696969696969696
layer1_out 500, delta 20, sigma 0.9, sim MSTKNN, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07578323036432266
val loss: 0.07391645759344101
EPOCH 21
train loss: 0.06477534025907516
val loss: 0.06441882997751236
EPOCH 41
train loss: 0.06299295276403427
val loss: 0.06347925215959549
early stopping...
2-NN
0.396871945259042
5-NN
0.4264418377321603
8-NN
0.42888563049853373
10-NN
0.4293743890518084
15-NN
0.43206256109481916
layer1_out 2000, delta 10, sigma 0.1, sim nnlsw, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07514302432537079
val loss: 0.07697051763534546
EPOCH 21
train loss: 0.063994862139225
val loss: 0.06600707769393921
EPOCH 41
train loss: 0.06327294558286667
val loss: 0.06557779759168625
EPOCH 61
train loss: 0.062318917363882065
val loss: 0.06509290635585785
EPOCH 81
train loss: 0.06040111929178238
val loss: 0.06356393545866013
EPOCH 101
train loss: 0.05785209313035011
val loss: 0.06137372925877571
EPOCH 121
train loss: 0.056002747267484665
val loss: 0.05984225496649742
EPOCH 141
train loss: 0.055086880922317505
val loss: 0.05917425453662872
EPOCH 161
train loss: 0.054559919983148575
val loss: 0.059016428887844086
EPOCH 181
train loss: 0.05417780950665474
val loss: 0.05894747003912926
2-NN
0.4281524926686217
5-NN
0.46480938416422285
8-NN
0.47214076246334313
10-NN
0.47702834799608995
15-NN
0.4802052785923754
layer1_out 2000, delta 10, sigma 0.1, sim nnlsw, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07466576248407364
val loss: 0.0765598863363266
EPOCH 21
train loss: 0.06397449225187302
val loss: 0.06622062623500824
EPOCH 41
train loss: 0.06323783844709396
val loss: 0.06585731357336044
EPOCH 61
train loss: 0.06218699365854263
val loss: 0.0652950182557106
EPOCH 81
train loss: 0.06008530408143997
val loss: 0.06373316049575806
EPOCH 101
train loss: 0.05744478851556778
val loss: 0.0615978017449379
EPOCH 121
train loss: 0.05564383417367935
val loss: 0.060212165117263794
EPOCH 141
train loss: 0.05469508096575737
val loss: 0.05966472253203392
EPOCH 161
train loss: 0.054085079580545425
val loss: 0.05950434133410454
EPOCH 181
train loss: 0.05366341397166252
val loss: 0.05946402624249458
2-NN
0.436950146627566
5-NN
0.4689638318670577
8-NN
0.47531769305962857
10-NN
0.4736070381231672
15-NN
0.47580645161290325
layer1_out 2000, delta 10, sigma 0.1, sim nnlsw, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.0759410709142685
val loss: 0.07571808248758316
EPOCH 21
train loss: 0.06303391605615616
val loss: 0.06464012712240219
EPOCH 41
train loss: 0.060168374329805374
val loss: 0.06445400416851044
EPOCH 61
train loss: 0.05659940093755722
val loss: 0.06456483155488968
EPOCH 81
train loss: 0.05248626694083214
val loss: 0.06410785764455795
EPOCH 101
train loss: 0.04847902059555054
val loss: 0.0631045550107956
EPOCH 121
train loss: 0.045608192682266235
val loss: 0.06258648633956909
EPOCH 141
train loss: 0.04376685246825218
val loss: 0.06278033554553986
EPOCH 161
train loss: 0.04244920611381531
val loss: 0.06309250742197037
EPOCH 181
train loss: 0.04146205633878708
val loss: 0.06353070586919785
2-NN
0.3704789833822092
5-NN
0.38269794721407624
8-NN
0.3775659824046921
10-NN
0.37561094819159335
15-NN
0.364613880742913
layer1_out 2000, delta 10, sigma 0.1, sim gaussian, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07589514553546906
val loss: 0.07521204650402069
EPOCH 21
train loss: 0.06162596493959427
val loss: 0.06384029239416122
early stopping...
2-NN
0.37854349951124144
5-NN
0.40762463343108507
8-NN
0.41275659824046923
10-NN
0.41275659824046923
15-NN
0.4056695992179863
layer1_out 2000, delta 10, sigma 0.1, sim gaussian, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07575913518667221
val loss: 0.07363974303007126
EPOCH 21
train loss: 0.06189781054854393
val loss: 0.06391853839159012
early stopping...
2-NN
0.3782991202346041
5-NN
0.4120234604105572
8-NN
0.4083577712609971
10-NN
0.4120234604105572
15-NN
0.41275659824046923
layer1_out 2000, delta 10, sigma 0.1, sim gaussian, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.0755806416273117
val loss: 0.07635025680065155
EPOCH 21
train loss: 0.06151249259710312
val loss: 0.06595110893249512
early stopping...
2-NN
0.3924731182795699
5-NN
0.4166666666666667
8-NN
0.416911045943304
10-NN
0.4166666666666667
15-NN
0.4112903225806452
layer1_out 2000, delta 10, sigma 0.1, sim MSTKNN, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: nan
val loss: nan
EPOCH 21
train loss: nan
val loss: nan
EPOCH 41
train loss: nan
val loss: nan
EPOCH 61
train loss: nan
val loss: nan
EPOCH 81
train loss: nan
val loss: nan
EPOCH 101
train loss: nan
val loss: nan
EPOCH 121
train loss: nan
val loss: nan
EPOCH 141
train loss: nan
val loss: nan
EPOCH 161
train loss: nan
val loss: nan
EPOCH 181
train loss: nan
val loss: nan
layer1_out 2000, delta 10, sigma 0.1, sim MSTKNN, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: nan
val loss: nan
EPOCH 21
train loss: nan
val loss: nan
EPOCH 41
train loss: nan
val loss: nan
EPOCH 61
train loss: nan
val loss: nan
EPOCH 81
train loss: nan
val loss: nan
EPOCH 101
train loss: nan
val loss: nan
EPOCH 121
train loss: nan
val loss: nan
EPOCH 141
train loss: nan
val loss: nan
EPOCH 161
train loss: nan
val loss: nan
EPOCH 181
train loss: nan
val loss: nan
layer1_out 2000, delta 10, sigma 0.1, sim MSTKNN, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: nan
val loss: nan
EPOCH 21
train loss: nan
val loss: nan
EPOCH 41
train loss: nan
val loss: nan
EPOCH 61
train loss: nan
val loss: nan
EPOCH 81
train loss: nan
val loss: nan
EPOCH 101
train loss: nan
val loss: nan
EPOCH 121
train loss: nan
val loss: nan
EPOCH 141
train loss: nan
val loss: nan
EPOCH 161
train loss: nan
val loss: nan
EPOCH 181
train loss: nan
val loss: nan
layer1_out 2000, delta 10, sigma 0.9, sim nnlsw, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.0750817283987999
val loss: 0.07526127994060516
EPOCH 21
train loss: 0.06414499133825302
val loss: 0.06462382525205612
EPOCH 41
train loss: 0.06346991658210754
val loss: 0.06421060115098953
EPOCH 61
train loss: 0.06252424418926239
val loss: 0.06370635330677032
EPOCH 81
train loss: 0.06060385704040527
val loss: 0.06233185902237892
EPOCH 101
train loss: 0.0580890066921711
val loss: 0.0603715255856514
EPOCH 121
train loss: 0.05624702572822571
val loss: 0.0590231716632843
EPOCH 141
train loss: 0.05526736378669739
val loss: 0.058484289795160294
EPOCH 161
train loss: 0.054708145558834076
val loss: 0.058453481644392014
EPOCH 181
train loss: 0.05434403195977211
val loss: 0.05844039097428322
2-NN
0.4274193548387097
5-NN
0.4626099706744868
8-NN
0.47336265884652984
10-NN
0.47531769305962857
15-NN
0.4809384164222874
layer1_out 2000, delta 10, sigma 0.9, sim nnlsw, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07505946606397629
val loss: 0.0764574483036995
EPOCH 21
train loss: 0.06414181739091873
val loss: 0.06501389294862747
EPOCH 41
train loss: 0.06343603134155273
val loss: 0.06454471498727798
EPOCH 61
train loss: 0.06249970197677612
val loss: 0.06409228593111038
EPOCH 81
train loss: 0.06061849743127823
val loss: 0.06273136287927628
EPOCH 101
train loss: 0.058107033371925354
val loss: 0.060661278665065765
EPOCH 121
train loss: 0.056134216487407684
val loss: 0.059209294617176056
EPOCH 141
train loss: 0.054959140717983246
val loss: 0.058435969054698944
EPOCH 161
train loss: 0.054231561720371246
val loss: 0.05814223363995552
EPOCH 181
train loss: 0.05372790992259979
val loss: 0.05801481008529663
2-NN
0.42888563049853373
5-NN
0.4696969696969697
8-NN
0.4809384164222874
10-NN
0.4767839687194526
15-NN
0.47751710654936463
layer1_out 2000, delta 10, sigma 0.9, sim nnlsw, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.0751979723572731
val loss: 0.07483002543449402
EPOCH 21
train loss: 0.06300922483205795
val loss: 0.06443551927804947
early stopping...
2-NN
0.4347507331378299
5-NN
0.46114369501466274
8-NN
0.46114369501466274
10-NN
0.46016617790811337
15-NN
0.46065493646138805
layer1_out 2000, delta 10, sigma 0.9, sim gaussian, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07577133178710938
val loss: 0.07659778743982315
EPOCH 21
train loss: 0.06415962427854538
val loss: 0.06504562497138977
EPOCH 41
train loss: 0.06369698792695999
val loss: 0.06460423022508621
EPOCH 61
train loss: 0.06328947842121124
val loss: 0.06419910490512848
EPOCH 81
train loss: 0.062412939965724945
val loss: 0.06328872591257095
EPOCH 101
train loss: 0.060902778059244156
val loss: 0.06170090287923813
EPOCH 121
train loss: 0.05922490358352661
val loss: 0.05993138626217842
EPOCH 141
train loss: 0.057933222502470016
val loss: 0.05856167525053024
EPOCH 161
train loss: 0.057132598012685776
val loss: 0.05774225294589996
EPOCH 181
train loss: 0.05668690800666809
val loss: 0.05725919455289841
2-NN
0.29056695992179865
5-NN
0.3409090909090909
8-NN
0.3514173998044966
10-NN
0.35459433040078203
15-NN
0.35166177908113394
layer1_out 2000, delta 10, sigma 0.9, sim gaussian, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07528416812419891
val loss: 0.07667781412601471
EPOCH 21
train loss: 0.06408055871725082
val loss: 0.06564430892467499
EPOCH 41
train loss: 0.063604936003685
val loss: 0.06513431668281555
EPOCH 61
train loss: 0.06316090375185013
val loss: 0.0647016167640686
EPOCH 81
train loss: 0.062215279787778854
val loss: 0.06377638131380081
EPOCH 101
train loss: 0.06061296910047531
val loss: 0.06217755004763603
EPOCH 121
train loss: 0.058871906250715256
val loss: 0.06047854572534561
EPOCH 141
train loss: 0.05755942687392235
val loss: 0.05924783647060394
EPOCH 161
train loss: 0.05680135637521744
val loss: 0.05853770300745964
EPOCH 181
train loss: 0.05637257173657417
val loss: 0.058137353509664536
2-NN
0.271505376344086
5-NN
0.3057184750733138
8-NN
0.32160312805474095
10-NN
0.3301564027370479
15-NN
0.3213587487781036
layer1_out 2000, delta 10, sigma 0.9, sim gaussian, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07513181120157242
val loss: 0.07359708100557327
EPOCH 21
train loss: 0.06336735934019089
val loss: 0.06298498064279556
EPOCH 41
train loss: 0.06070873141288757
val loss: 0.06283459067344666
EPOCH 61
train loss: 0.057244397699832916
val loss: 0.06290557235479355
EPOCH 81
train loss: 0.05310702323913574
val loss: 0.0623273141682148
EPOCH 101
train loss: 0.049263667315244675
val loss: 0.06135055050253868
EPOCH 121
train loss: 0.04667949303984642
val loss: 0.061068274080753326
EPOCH 141
train loss: 0.045038092881441116
val loss: 0.06160883232951164
EPOCH 161
train loss: 0.04378252476453781
val loss: 0.062134094536304474
early stopping...
2-NN
0.3032746823069404
5-NN
0.3301564027370479
8-NN
0.3225806451612903
10-NN
0.3189149560117302
15-NN
0.31378299120234604
layer1_out 2000, delta 10, sigma 0.9, sim MSTKNN, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07597152143716812
val loss: 0.07319808006286621
EPOCH 21
train loss: 0.064481221139431
val loss: 0.06245553866028786
EPOCH 41
train loss: 0.06394851207733154
val loss: 0.06217346340417862
EPOCH 61
train loss: 0.06343819946050644
val loss: 0.06194659322500229
EPOCH 81
train loss: 0.062411025166511536
val loss: 0.061084989458322525
EPOCH 101
train loss: 0.060730207711458206
val loss: 0.05956697836518288
EPOCH 121
train loss: 0.05895283818244934
val loss: 0.057955216616392136
EPOCH 141
train loss: 0.05765786021947861
val loss: 0.056763045489788055
EPOCH 161
train loss: 0.05690751597285271
val loss: 0.05613413453102112
EPOCH 181
train loss: 0.05647055804729462
val loss: 0.05582975596189499
2-NN
0.37072336265884653
5-NN
0.4208211143695015
8-NN
0.4293743890518084
10-NN
0.43328445747800587
15-NN
0.43841642228739003
layer1_out 2000, delta 10, sigma 0.9, sim MSTKNN, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07636910676956177
val loss: 0.07073845714330673
EPOCH 21
train loss: 0.06478430330753326
val loss: 0.05989331752061844
EPOCH 41
train loss: 0.06426791101694107
val loss: 0.05957452952861786
EPOCH 61
train loss: 0.06377746909856796
val loss: 0.05930982157588005
EPOCH 81
train loss: 0.0627979263663292
val loss: 0.05854363739490509
EPOCH 101
train loss: 0.06109537184238434
val loss: 0.05712788179516792
EPOCH 121
train loss: 0.059189699590206146
val loss: 0.05554518476128578
EPOCH 141
train loss: 0.05774832144379616
val loss: 0.05448742210865021
EPOCH 161
train loss: 0.05686509609222412
val loss: 0.05398343876004219
EPOCH 181
train loss: 0.056368954479694366
val loss: 0.05375172197818756
2-NN
0.38098729227761485
5-NN
0.43010752688172044
8-NN
0.4423264907135875
10-NN
0.4459921798631476
15-NN
0.4513685239491691
layer1_out 2000, delta 10, sigma 0.9, sim MSTKNN, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07613790780305862
val loss: 0.07135563343763351
EPOCH 21
train loss: 0.06347758322954178
val loss: 0.06116082891821861
EPOCH 41
train loss: 0.06072190776467323
val loss: 0.0611085407435894
EPOCH 61
train loss: 0.05728008598089218
val loss: 0.06111639738082886
EPOCH 81
train loss: 0.053166527301073074
val loss: 0.06072227656841278
EPOCH 101
train loss: 0.04923844337463379
val loss: 0.06030946597456932
EPOCH 121
train loss: 0.04649000242352486
val loss: 0.06052672117948532
EPOCH 141
train loss: 0.04480326548218727
val loss: 0.06105751916766167
EPOCH 161
train loss: 0.04350675642490387
val loss: 0.06177579611539841
EPOCH 181
train loss: 0.04251043498516083
val loss: 0.06255774199962616
2-NN
0.34237536656891493
5-NN
0.3629032258064516
8-NN
0.35459433040078203
10-NN
0.35117302052785926
15-NN
0.3455522971652004
layer1_out 2000, delta 20, sigma 0.1, sim nnlsw, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07532058656215668
val loss: 0.07532380521297455
EPOCH 21
train loss: 0.06416450440883636
val loss: 0.0650210976600647
EPOCH 41
train loss: 0.06350009143352509
val loss: 0.06476797163486481
EPOCH 61
train loss: 0.06267762184143066
val loss: 0.0643567442893982
EPOCH 81
train loss: 0.06098334118723869
val loss: 0.06313677877187729
EPOCH 101
train loss: 0.0584946908056736
val loss: 0.0611388273537159
EPOCH 121
train loss: 0.056470975279808044
val loss: 0.059615492820739746
EPOCH 141
train loss: 0.055314697325229645
val loss: 0.05890917778015137
EPOCH 161
train loss: 0.05469340458512306
val loss: 0.058658771216869354
EPOCH 181
train loss: 0.05428769066929817
val loss: 0.05863635241985321
2-NN
0.427663734115347
5-NN
0.46358748778103614
8-NN
0.47165200391006845
10-NN
0.47116324535679377
15-NN
0.47531769305962857
layer1_out 2000, delta 20, sigma 0.1, sim nnlsw, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07552662491798401
val loss: 0.07746399939060211
EPOCH 21
train loss: 0.06410792469978333
val loss: 0.06535086780786514
EPOCH 41
train loss: 0.06341737508773804
val loss: 0.06495092064142227
EPOCH 61
train loss: 0.06253179907798767
val loss: 0.06455691903829575
EPOCH 81
train loss: 0.06074502691626549
val loss: 0.06329654157161713
EPOCH 101
train loss: 0.05821879580616951
val loss: 0.06121855601668358
EPOCH 121
train loss: 0.05623016878962517
val loss: 0.05970042571425438
EPOCH 141
train loss: 0.05507225915789604
val loss: 0.05894305184483528
EPOCH 161
train loss: 0.05440852791070938
val loss: 0.058696944266557693
EPOCH 181
train loss: 0.0539725087583065
val loss: 0.05868452042341232
2-NN
0.4381720430107527
5-NN
0.46725317693059626
8-NN
0.4694525904203324
10-NN
0.47116324535679377
15-NN
0.4750733137829912
layer1_out 2000, delta 20, sigma 0.1, sim nnlsw, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07560758292675018
val loss: 0.07415145635604858
EPOCH 21
train loss: 0.06306149065494537
val loss: 0.06476514041423798
early stopping...
2-NN
0.4418377321603128
5-NN
0.4723851417399805
8-NN
0.47873900293255134
10-NN
0.48167155425219943
15-NN
0.4797165200391007
layer1_out 2000, delta 20, sigma 0.1, sim gaussian, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.0754830464720726
val loss: 0.07414507865905762
EPOCH 21
train loss: 0.06185702234506607
val loss: 0.0624840185046196
early stopping...
2-NN
0.3712121212121212
5-NN
0.40860215053763443
8-NN
0.4078690127077224
10-NN
0.4100684261974585
15-NN
0.40762463343108507
layer1_out 2000, delta 20, sigma 0.1, sim gaussian, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07601558417081833
val loss: 0.07503500580787659
EPOCH 21
train loss: 0.06172000244259834
val loss: 0.06385111063718796
EPOCH 41
train loss: 0.057568542659282684
val loss: 0.06403548270463943
early stopping...
2-NN
0.3736559139784946
5-NN
0.4002932551319648
8-NN
0.4002932551319648
10-NN
0.4044477028347996
15-NN
0.4027370478983382
layer1_out 2000, delta 20, sigma 0.1, sim gaussian, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07506643980741501
val loss: 0.07762881368398666
EPOCH 21
train loss: 0.06140214577317238
val loss: 0.06775040924549103
early stopping...
2-NN
0.39540566959921797
5-NN
0.4156891495601173
8-NN
0.41104594330400784
10-NN
0.416177908113392
15-NN
0.4149560117302053
layer1_out 2000, delta 20, sigma 0.1, sim MSTKNN, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: nan
val loss: nan
EPOCH 21
train loss: nan
val loss: nan
EPOCH 41
train loss: nan
val loss: nan
EPOCH 61
train loss: nan
val loss: nan
EPOCH 81
train loss: nan
val loss: nan
EPOCH 101
train loss: nan
val loss: nan
EPOCH 121
train loss: nan
val loss: nan
EPOCH 141
train loss: nan
val loss: nan
EPOCH 161
train loss: nan
val loss: nan
EPOCH 181
train loss: nan
val loss: nan
layer1_out 2000, delta 20, sigma 0.1, sim MSTKNN, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: nan
val loss: nan
EPOCH 21
train loss: nan
val loss: nan
EPOCH 41
train loss: nan
val loss: nan
EPOCH 61
train loss: nan
val loss: nan
EPOCH 81
train loss: nan
val loss: nan
EPOCH 101
train loss: nan
val loss: nan
EPOCH 121
train loss: nan
val loss: nan
EPOCH 141
train loss: nan
val loss: nan
EPOCH 161
train loss: nan
val loss: nan
EPOCH 181
train loss: nan
val loss: nan
layer1_out 2000, delta 20, sigma 0.1, sim MSTKNN, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: nan
val loss: nan
EPOCH 21
train loss: nan
val loss: nan
EPOCH 41
train loss: nan
val loss: nan
EPOCH 61
train loss: nan
val loss: nan
EPOCH 81
train loss: nan
val loss: nan
EPOCH 101
train loss: nan
val loss: nan
EPOCH 121
train loss: nan
val loss: nan
EPOCH 141
train loss: nan
val loss: nan
EPOCH 161
train loss: nan
val loss: nan
EPOCH 181
train loss: nan
val loss: nan
layer1_out 2000, delta 20, sigma 0.9, sim nnlsw, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.0755210742354393
val loss: 0.0751996859908104
EPOCH 21
train loss: 0.06430108845233917
val loss: 0.06380462646484375
EPOCH 41
train loss: 0.06364015489816666
val loss: 0.063410684466362
EPOCH 61
train loss: 0.06283607333898544
val loss: 0.0630338042974472
EPOCH 81
train loss: 0.06123115122318268
val loss: 0.06183008849620819
EPOCH 101
train loss: 0.058929331600666046
val loss: 0.05985218286514282
EPOCH 121
train loss: 0.05693616345524788
val loss: 0.05815904214978218
EPOCH 141
train loss: 0.05575941130518913
val loss: 0.05728307366371155
EPOCH 161
train loss: 0.0550667941570282
val loss: 0.05695324018597603
EPOCH 181
train loss: 0.054621025919914246
val loss: 0.056912340223789215
2-NN
0.4198435972629521
5-NN
0.459188660801564
8-NN
0.4608993157380254
10-NN
0.46920821114369504
15-NN
0.4760508308895406
layer1_out 2000, delta 20, sigma 0.9, sim nnlsw, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07539952546358109
val loss: 0.0746801421046257
EPOCH 21
train loss: 0.06417332589626312
val loss: 0.06407160311937332
EPOCH 41
train loss: 0.06346675008535385
val loss: 0.06369145214557648
EPOCH 61
train loss: 0.06247236952185631
val loss: 0.06320517510175705
EPOCH 81
train loss: 0.060483817011117935
val loss: 0.06181676685810089
EPOCH 101
train loss: 0.05786028876900673
val loss: 0.059789348393678665
EPOCH 121
train loss: 0.055955108255147934
val loss: 0.058364447206258774
EPOCH 141
train loss: 0.05493221804499626
val loss: 0.05769502744078636
EPOCH 161
train loss: 0.05430186912417412
val loss: 0.057476144284009933
EPOCH 181
train loss: 0.05385267361998558
val loss: 0.05743616446852684
2-NN
0.43670576735092864
5-NN
0.4701857282502444
8-NN
0.47409579667644186
10-NN
0.48118279569892475
15-NN
0.4821603128054741
layer1_out 2000, delta 20, sigma 0.9, sim nnlsw, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07569523900747299
val loss: 0.07307737320661545
EPOCH 21
train loss: 0.06330163031816483
val loss: 0.062441062182188034
EPOCH 41
train loss: 0.060443684458732605
val loss: 0.06232323497533798
early stopping...
2-NN
0.42130987292277616
5-NN
0.45698924731182794
8-NN
0.45894428152492667
10-NN
0.4525904203323558
15-NN
0.45161290322580644
layer1_out 2000, delta 20, sigma 0.9, sim gaussian, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07570134848356247
val loss: 0.07378976792097092
EPOCH 21
train loss: 0.06446919590234756
val loss: 0.06264728307723999
EPOCH 41
train loss: 0.06400080025196075
val loss: 0.06222940608859062
EPOCH 61
train loss: 0.06361294537782669
val loss: 0.06181156635284424
EPOCH 81
train loss: 0.06283984333276749
val loss: 0.0609816238284111
EPOCH 101
train loss: 0.061512332409620285
val loss: 0.05954080820083618
EPOCH 121
train loss: 0.05997290089726448
val loss: 0.057857781648635864
EPOCH 141
train loss: 0.05871502310037613
val loss: 0.05646352097392082
EPOCH 161
train loss: 0.05785797908902168
val loss: 0.055529188364744186
EPOCH 181
train loss: 0.05730564519762993
val loss: 0.05490037798881531
2-NN
0.2763929618768328
5-NN
0.32160312805474095
8-NN
0.3355327468230694
10-NN
0.33357771260997066
15-NN
0.3304007820136852
layer1_out 2000, delta 20, sigma 0.9, sim gaussian, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.0740998312830925
val loss: 0.08348657935857773
EPOCH 21
train loss: 0.06332200020551682
val loss: 0.07194298505783081
EPOCH 41
train loss: 0.06282903254032135
val loss: 0.07141148298978806
EPOCH 61
train loss: 0.06229289993643761
val loss: 0.07082538306713104
EPOCH 81
train loss: 0.06109619140625
val loss: 0.06953384727239609
EPOCH 101
train loss: 0.05923941731452942
val loss: 0.06744769215583801
EPOCH 121
train loss: 0.05757329612970352
val loss: 0.06551451236009598
EPOCH 141
train loss: 0.056565381586551666
val loss: 0.06437743455171585
EPOCH 161
train loss: 0.056026890873909
val loss: 0.0637698620557785
EPOCH 181
train loss: 0.055829279124736786
val loss: 0.06352760642766953
2-NN
0.27370478983382207
5-NN
0.3128054740957967
8-NN
0.3279569892473118
10-NN
0.33113391984359725
15-NN
0.322336265884653
layer1_out 2000, delta 20, sigma 0.9, sim gaussian, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.0753442645072937
val loss: 0.07584243267774582
EPOCH 21
train loss: 0.06322792172431946
val loss: 0.06473547220230103
EPOCH 41
train loss: 0.0606972835958004
val loss: 0.0645008310675621
EPOCH 61
train loss: 0.05731423199176788
val loss: 0.06446853280067444
EPOCH 81
train loss: 0.05320657417178154
val loss: 0.06401010602712631
EPOCH 101
train loss: 0.049290455877780914
val loss: 0.06327441334724426
EPOCH 121
train loss: 0.04659409448504448
val loss: 0.06345850229263306
EPOCH 141
train loss: 0.04485637694597244
val loss: 0.06382349878549576
EPOCH 161
train loss: 0.04365658015012741
val loss: 0.06472400575876236
EPOCH 181
train loss: 0.042716752737760544
val loss: 0.06579218804836273
2-NN
0.3047409579667644
5-NN
0.33186705767350927
8-NN
0.32942326490713586
10-NN
0.33162267839687193
15-NN
0.3196480938416422
layer1_out 2000, delta 20, sigma 0.9, sim MSTKNN, alpha 0.0
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07565683871507645
val loss: 0.07332924008369446
EPOCH 21
train loss: 0.06441240757703781
val loss: 0.0626288577914238
EPOCH 41
train loss: 0.06388802826404572
val loss: 0.0622568279504776
EPOCH 61
train loss: 0.06331174075603485
val loss: 0.06185241416096687
EPOCH 81
train loss: 0.06208956986665726
val loss: 0.06070135906338692
EPOCH 101
train loss: 0.06015054136514664
val loss: 0.058866068720817566
EPOCH 121
train loss: 0.05829833447933197
val loss: 0.05719918757677078
EPOCH 141
train loss: 0.057160597294569016
val loss: 0.05623197555541992
EPOCH 161
train loss: 0.05658538639545441
val loss: 0.055877380073070526
EPOCH 181
train loss: 0.056277528405189514
val loss: 0.055743634700775146
2-NN
0.36070381231671556
5-NN
0.41813294232649073
8-NN
0.43132942326490714
10-NN
0.43304007820136853
15-NN
0.43841642228739003
layer1_out 2000, delta 20, sigma 0.9, sim MSTKNN, alpha 0.1
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07531560212373734
val loss: 0.07209637761116028
EPOCH 21
train loss: 0.06453568488359451
val loss: 0.06161323934793472
EPOCH 41
train loss: 0.06397556513547897
val loss: 0.061231229454278946
EPOCH 61
train loss: 0.06335936486721039
val loss: 0.060839731246232986
EPOCH 81
train loss: 0.06209462881088257
val loss: 0.0597684271633625
EPOCH 101
train loss: 0.06010088324546814
val loss: 0.05795837566256523
EPOCH 121
train loss: 0.05819633975625038
val loss: 0.05620775744318962
EPOCH 141
train loss: 0.057040754705667496
val loss: 0.05514209717512131
EPOCH 161
train loss: 0.05647726729512215
val loss: 0.05471822991967201
EPOCH 181
train loss: 0.05617161840200424
val loss: 0.054547958076000214
2-NN
0.38514173998044965
5-NN
0.42839687194525905
8-NN
0.44330400782013685
10-NN
0.44330400782013685
15-NN
0.4411045943304008
layer1_out 2000, delta 20, sigma 0.9, sim MSTKNN, alpha 0.7
training: 687 points
validation: 77 points
EPOCH 1
train loss: 0.07517234236001968
val loss: 0.07573950290679932
EPOCH 21
train loss: 0.06293189525604248
val loss: 0.06582889705896378
EPOCH 41
train loss: 0.06019004434347153
val loss: 0.06584727019071579
early stopping...
2-NN
0.3956500488758553
5-NN
0.43499511241446726
8-NN
0.43377321603128055
10-NN
0.43377321603128055
15-NN
0.4323069403714565
