{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Accelerate code running via CPU multiprocessing. \n",
    "Shibo Yao, Oct. 25 2020\n",
    "In here we assume there is no modification on the graph like what I did in\n",
    "Latent Semantic Imputation, as the neural units and backpropogation in GCN\n",
    "can handle the deviation of those known guys. \n",
    "A comparison between w/without modification on graph can be carried out later.\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd #can remove when not testing\n",
    "from scipy.optimize import nnls\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "import multiprocessing as mp\n",
    "\n",
    "\n",
    "\n",
    "def dis_base(pid, index, return_dic, x):\n",
    "    '''\n",
    "    the base for Euclidean distance matrix calculation\n",
    "    pid: process ID, index: matrix row index, return_dic: result container\n",
    "    x: feature matrix being shared by all processes\n",
    "    '''\n",
    "    p = len(index)\n",
    "    n = x.shape[0]\n",
    "    small_dis = np.zeros([p,n])\n",
    "    for i in range(p):\n",
    "        vec = x[index[i]]\n",
    "        small_dis[i] = [np.linalg.norm(vec-x[j]) for j in range(n)]\n",
    "\n",
    "    return_dic[pid] = small_dis\n",
    "\n",
    "\n",
    "def distanceEuclidean(x, Q_index, n_jobs, func=dis_base):\n",
    "    '''\n",
    "    multiprocessing Euclidean distance matrix calculation\n",
    "    x: feature matrix, Q_index: index of unknown guys(to impute)\n",
    "    for now always use the full index for Q_index\n",
    "    n_jobs: number of jobs, default number of processes on CPU\n",
    "    '''\n",
    "    total_cpu = mp.cpu_count()\n",
    "    if type(n_jobs) is not int or n_jobs < -1 or n_jobs > total_cpu:\n",
    "        print(\"Specify correct job number!\")\n",
    "        exit(0)\n",
    "    elif n_jobs==-1:\n",
    "        n_jobs = total_cpu\n",
    "\n",
    "    index_list = np.array_split(Q_index, n_jobs)\n",
    "    processes = []\n",
    "    return_dic = mp.Manager().dict()\n",
    "\n",
    "    for i in range(n_jobs):\n",
    "        proc = mp.Process(target=func, args=(i,index_list[i],return_dic,x))\n",
    "        processes.append(proc)\n",
    "        proc.start()\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "\n",
    "    dis_mat = [return_dic[i] for i in range(n_jobs)]\n",
    "    dis_mat = np.concatenate(dis_mat, axis=0)\n",
    "    \n",
    "    return dis_mat\n",
    "\n",
    "\n",
    "def kerGauss(dis, sigma):\n",
    "    '''\n",
    "    similarity matrix given by Gaussian kernel\n",
    "    dis: Euclidean matrix, sigma: same as in Gaussian kernel\n",
    "    '''\n",
    "    s = sigma**2\n",
    "    return np.exp(-dis ** 2 / s)\n",
    "\n",
    "\n",
    "def MST(dis, Q_index):\n",
    "    '''\n",
    "    minimum spanning tree based on Euclidean matrix\n",
    "    return a zero-one graph\n",
    "    '''\n",
    "    dis = dis[:, Q_index]\n",
    "    d = csr_matrix(dis.astype('float'))\n",
    "    Tcsr = minimum_spanning_tree(d)\n",
    "    del d\n",
    "    mpn = Tcsr.toarray().astype(float)\n",
    "    del Tcsr\n",
    "    mpn[mpn!=0] = 1\n",
    "    n = dis.shape[0]\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if mpn[i,j] != 0:\n",
    "                mpn[j,i] = 1\n",
    "\n",
    "    return mpn\n",
    "\n",
    "\n",
    "def mst_knn_base(pid, index, dis, mpn, delta, return_dic):\n",
    "    '''\n",
    "    base for minimum-spanning-tree-k-nearest-neighbor graph\n",
    "    pid: process ID, index: --, mpn: minimum spanning tree\n",
    "    dis: Euclidean distance matrix, delta: node in-degree\n",
    "    return_dic: result container\n",
    "    '''\n",
    "    n = len(index)\n",
    "    small_graph = mpn[index]\n",
    "    \n",
    "    for i in range(n):\n",
    "        ind = index[i]\n",
    "        nn_index = np.argsort(dis[ind])[1:(delta+1)]\n",
    "        degree = small_graph[i].sum()\n",
    "        j = 0\n",
    "        while degree < delta:\n",
    "            if small_graph[i, nn_index[j]] == 0:\n",
    "                small_graph[i, nn_index[j]] = 1\n",
    "                degree += 1\n",
    "            j += 1\n",
    "\n",
    "    return_dic[pid] = small_graph\n",
    "\n",
    "\n",
    "def MSTKNN(dis, Q_index, delta, n_jobs, spanning=True, func=mst_knn_base):\n",
    "    '''\n",
    "    minimum spanning tree k nearest neighbor graph\n",
    "    when spanning is false, it degenrates to KNN graph, hence delta is k\n",
    "    zero - one graph\n",
    "    '''\n",
    "    total_cpu = mp.cpu_count()\n",
    "    if type(n_jobs) is not int or n_jobs < -1 or n_jobs > total_cpu:\n",
    "        print(\"Specify correct job number!\")\n",
    "        exit(0)\n",
    "    elif n_jobs==-1:\n",
    "        n_jobs = total_cpu\n",
    "    \n",
    "    mpn = np.zeros(dis.shape)\n",
    "    if spanning:\n",
    "        mst = MST(dis, Q_index)\n",
    "        mpn[:,Q_index[0]:] = mst\n",
    "    \n",
    "    index_list = np.array_split(range(len(Q_index)), n_jobs)\n",
    "    processes = []\n",
    "    return_dic = mp.Manager().dict()\n",
    "\n",
    "    for i in range(n_jobs):\n",
    "        proc = mp.Process(target=func, args=(i,index_list[i],dis,mpn,delta,return_dic))\n",
    "        processes.append(proc)\n",
    "        proc.start()\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "\n",
    "    graph = [return_dic[i] for i in range(n_jobs)]\n",
    "    graph = np.concatenate(graph, axis=0)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "    \n",
    "def nnlsw(X, graph, pid, sub_list, return_dic, epsilon):\n",
    "    '''\n",
    "    X: feature matrix, graph: what ever zero-one graph\n",
    "    epsilon: small nonnegative that cures singularity\n",
    "    '''\n",
    "    nrows = len(sub_list)\n",
    "    ncols = graph.shape[1]\n",
    "    W = np.zeros((nrows, ncols))\n",
    "    for i in range(nrows):\n",
    "        ind_i = sub_list[i]\n",
    "        vec = X[ind_i]#b vector in scipy documentation\n",
    "        gvec = graph[ind_i]\n",
    "        indK = [j for j in range(ncols) if gvec[j] == 1]\n",
    "        delta = len(indK) \n",
    "        mat = X[indK]#A matrix in scipy documentation\n",
    "        w = nnls(mat.T, vec)[0]#return both weights and residual\n",
    "        if epsilon is not None:\n",
    "            tmp = w[w!=0].copy()\n",
    "            w = w + epsilon*min(tmp)#all neighbors nonzero\n",
    "        if sum(w)==0: #in case funny things happen\n",
    "            w = np.ones(len(w))\n",
    "        w = w/sum(w) #need to normalize, w bounded between 0 and 1\n",
    "    \n",
    "        for ii in range(delta):\n",
    "            W[i, indK[ii]] = w[ii]\n",
    "    \n",
    "    return_dic[pid] = W\n",
    "\n",
    "\n",
    "def multicoreNNLS(X, graph, Q_index, n_jobs, epsilon=1e-1, func=nnlsw):\n",
    "    '''\n",
    "    nonnegative least square \n",
    "    return a weighted (unnormalized) nonnegative graph\n",
    "    '''\n",
    "    total_cpu = mp.cpu_count()\n",
    "    if type(n_jobs) is not int or n_jobs < -1 or n_jobs > total_cpu:\n",
    "        print(\"Specify correct job number!\")\n",
    "        exit(0)\n",
    "    elif n_jobs==-1:\n",
    "        n_jobs = total_cpu\n",
    "\n",
    "    graph_list = np.array_split(range(len(Q_index)), n_jobs)#default axis=0\n",
    "    processes = []\n",
    "    return_dic = mp.Manager().dict()\n",
    "\n",
    "    for i in range(n_jobs):\n",
    "        proc = mp.Process(target=func, args=(X,graph,i,graph_list[i],return_dic,epsilon))\n",
    "        processes.append(proc)\n",
    "        proc.start()\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "\n",
    "    W_p = np.eye(X.shape[0]-graph.shape[0], graph.shape[1])\n",
    "    W_q = [return_dic[i] for i in range(n_jobs)]\n",
    "    W_q = np.concatenate(W_q, axis=0)\n",
    "\n",
    "    return np.concatenate([W_p,W_q], axis=0)\n",
    "\n",
    "\n",
    "def RandomWalkNormalize(A):\n",
    "    D = A.sum(1) # row sum, degree vector\n",
    "    return A / D.reshape(-1,1)\n",
    "\n",
    "\n",
    "def lazy(W, alpha=.5):\n",
    "    '''\n",
    "    lazy walk, add self loop to nodes / add constant to diagonal\n",
    "    alpha: the weight of self-loops\n",
    "    '''\n",
    "    return W*(1-alpha) + np.eye(W.shape[0])*alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel similarity row normalize\n",
      "True True\n",
      "MSTKNN kernel row normalize\n",
      "True True\n",
      "KNN kernel row normalize\n",
      "True True\n",
      "MSTKNN NNLS row normalize\n",
      "True True\n",
      "KNN NNLS row normalize\n",
      "True True\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1.]\n",
      "lazy walk matrix\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/sp500/affMat.csv\", index_col=0)\n",
    "X = df.values[:,:-1] #consider X a graph or a feature matrix, both fine\n",
    "np.fill_diagonal(X,0) #set diagonal to zero / remove self loops\n",
    "Q_index = range(X.shape[0]) # for now always use this\n",
    "\n",
    "dis = distanceEuclidean(X, Q_index, n_jobs=-1)\n",
    "similarity = kerGauss(dis, sigma=1.) #try different sigma\n",
    "\n",
    "## some examples\n",
    "# origianl similarity matrix, using gaussian kernel, row normalize\n",
    "A_kernel_norm = RandomWalkNormalize(similarity)\n",
    "# MSTKNN graph, using gaussian kernel, row normalize\n",
    "A_MSTKNN = MSTKNN(dis,Q_index,delta=20,n_jobs=-1,spanning=True)\n",
    "A_MSTKNN_ker = A_MSTKNN*similarity\n",
    "A_MSTKNN_norm = RandomWalkNormalize(A_MSTKNN_ker)\n",
    "# KNN graph, using gaussian kernel, row normalize\n",
    "A_KNN = MSTKNN(dis,Q_index,delta=20,n_jobs=-1,spanning=False)\n",
    "A_KNN_ker = A_KNN*similarity\n",
    "A_KNN_norm = RandomWalkNormalize(A_KNN_ker)\n",
    "# MSTKNN graph, NNLS, row normalize\n",
    "A_MSTKNN_nnls = multicoreNNLS(X,A_MSTKNN,Q_index,n_jobs=-1)\n",
    "# KNN graph, NNLS, row normalize\n",
    "A_KNN_nnls = multicoreNNLS(X,A_KNN,Q_index,n_jobs=-1)\n",
    "\n",
    "print(\"kernel similarity row normalize\")\n",
    "print(abs(A_kernel_norm[0].sum()-1) < 1e-7, (A_kernel_norm<0).sum()==0)\n",
    "print(\"MSTKNN kernel row normalize\")\n",
    "print(abs(A_MSTKNN_norm[0].sum()-1) < 1e-7, (A_MSTKNN_norm<0).sum()==0)\n",
    "print(\"KNN kernel row normalize\")\n",
    "print(abs(A_KNN_norm[0].sum()-1) < 1e-7, (A_KNN_norm<0).sum()==0)\n",
    "print(\"MSTKNN NNLS row normalize\")\n",
    "print(abs(A_MSTKNN_nnls[0].sum()-1) < 1e-7, (A_MSTKNN_nnls<0).sum()==0)\n",
    "print(\"KNN NNLS row normalize\")\n",
    "print(abs(A_KNN_nnls[0].sum()-1) < 1e-7, (A_KNN_nnls<0).sum()==0)\n",
    "\n",
    "print(A_KNN_nnls.sum(1)) # can have some float error\n",
    "\n",
    "A_lazy = lazy(A_KNN_nnls, alpha=.5) # can switch to any A_* above\n",
    "print(\"lazy walk matrix\")\n",
    "print(abs(A_lazy[0].sum()-1) < 1e-7, (A_lazy<0).sum()==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0. , 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0.5, 0. , ..., 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0.5, ..., 0. , 0. , 0. ],\n",
       "       ...,\n",
       "       [0. , 0. , 0. , ..., 0.5, 0. , 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0.5, 0. ],\n",
       "       [0. , 0. , 0. , ..., 0. , 0. , 0.5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,23,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fdefa71726e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "x[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
